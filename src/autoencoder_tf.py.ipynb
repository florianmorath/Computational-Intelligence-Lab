{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autoencoder tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tobiasgrob/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "/Users/tobiasgrob/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_nr: 0, train_loss: 1.436, test_loss: 1.020\n",
      "epoch_nr: 1, train_loss: 1.033, test_loss: 1.021\n",
      "epoch_nr: 2, train_loss: 1.033, test_loss: 1.021\n",
      "epoch_nr: 3, train_loss: 1.034, test_loss: 1.023\n",
      "epoch_nr: 4, train_loss: 1.035, test_loss: 1.021\n",
      "epoch_nr: 5, train_loss: 1.035, test_loss: 1.024\n",
      "epoch_nr: 6, train_loss: 1.036, test_loss: 1.023\n",
      "epoch_nr: 7, train_loss: 1.035, test_loss: 1.023\n",
      "epoch_nr: 8, train_loss: 1.036, test_loss: 1.023\n",
      "epoch_nr: 9, train_loss: 1.036, test_loss: 1.023\n",
      "epoch_nr: 10, train_loss: 1.037, test_loss: 1.022\n",
      "epoch_nr: 11, train_loss: 1.036, test_loss: 1.023\n",
      "epoch_nr: 12, train_loss: 1.036, test_loss: 1.023\n",
      "epoch_nr: 13, train_loss: 1.036, test_loss: 1.022\n",
      "epoch_nr: 14, train_loss: 1.036, test_loss: 1.021\n",
      "epoch_nr: 15, train_loss: 1.036, test_loss: 1.022\n",
      "epoch_nr: 16, train_loss: 1.036, test_loss: 1.022\n",
      "epoch_nr: 17, train_loss: 1.035, test_loss: 1.022\n",
      "epoch_nr: 18, train_loss: 1.036, test_loss: 1.021\n",
      "epoch_nr: 19, train_loss: 1.035, test_loss: 1.023\n",
      "epoch_nr: 20, train_loss: 1.035, test_loss: 1.022\n",
      "epoch_nr: 21, train_loss: 1.035, test_loss: 1.021\n",
      "epoch_nr: 22, train_loss: 1.035, test_loss: 1.021\n",
      "epoch_nr: 23, train_loss: 1.035, test_loss: 1.022\n",
      "epoch_nr: 24, train_loss: 1.035, test_loss: 1.021\n",
      "epoch_nr: 25, train_loss: 1.033, test_loss: 1.029\n",
      "epoch_nr: 26, train_loss: 1.028, test_loss: 1.027\n",
      "epoch_nr: 27, train_loss: 1.023, test_loss: 1.032\n",
      "epoch_nr: 28, train_loss: 1.020, test_loss: 1.034\n",
      "epoch_nr: 29, train_loss: 1.016, test_loss: 1.038\n",
      "epoch_nr: 30, train_loss: 1.016, test_loss: 1.037\n",
      "epoch_nr: 31, train_loss: 1.013, test_loss: 1.039\n",
      "epoch_nr: 32, train_loss: 1.012, test_loss: 1.039\n",
      "epoch_nr: 33, train_loss: 1.011, test_loss: 1.041\n",
      "epoch_nr: 34, train_loss: 1.010, test_loss: 1.041\n",
      "epoch_nr: 35, train_loss: 1.009, test_loss: 1.038\n",
      "epoch_nr: 36, train_loss: 1.009, test_loss: 1.042\n",
      "epoch_nr: 37, train_loss: 1.008, test_loss: 1.045\n",
      "epoch_nr: 38, train_loss: 1.008, test_loss: 1.044\n",
      "epoch_nr: 39, train_loss: 1.007, test_loss: 1.044\n",
      "epoch_nr: 40, train_loss: 1.006, test_loss: 1.044\n",
      "epoch_nr: 41, train_loss: 1.005, test_loss: 1.048\n",
      "epoch_nr: 42, train_loss: 1.005, test_loss: 1.048\n",
      "epoch_nr: 43, train_loss: 1.005, test_loss: 1.046\n",
      "epoch_nr: 44, train_loss: 1.004, test_loss: 1.046\n",
      "epoch_nr: 45, train_loss: 1.003, test_loss: 1.045\n",
      "epoch_nr: 46, train_loss: 1.002, test_loss: 1.046\n",
      "epoch_nr: 47, train_loss: 1.002, test_loss: 1.049\n",
      "epoch_nr: 48, train_loss: 1.001, test_loss: 1.050\n",
      "epoch_nr: 49, train_loss: 1.000, test_loss: 1.047\n",
      "epoch_nr: 50, train_loss: 1.000, test_loss: 1.049\n",
      "epoch_nr: 51, train_loss: 1.000, test_loss: 1.048\n",
      "epoch_nr: 52, train_loss: 0.999, test_loss: 1.050\n",
      "epoch_nr: 53, train_loss: 0.998, test_loss: 1.048\n",
      "epoch_nr: 54, train_loss: 0.999, test_loss: 1.051\n",
      "epoch_nr: 55, train_loss: 0.997, test_loss: 1.048\n",
      "epoch_nr: 56, train_loss: 0.996, test_loss: 1.047\n",
      "epoch_nr: 57, train_loss: 0.995, test_loss: 1.051\n",
      "epoch_nr: 58, train_loss: 0.993, test_loss: 1.052\n",
      "epoch_nr: 59, train_loss: 0.992, test_loss: 1.052\n",
      "epoch_nr: 60, train_loss: 0.990, test_loss: 1.055\n",
      "epoch_nr: 61, train_loss: 0.989, test_loss: 1.059\n",
      "epoch_nr: 62, train_loss: 0.988, test_loss: 1.058\n",
      "epoch_nr: 63, train_loss: 0.987, test_loss: 1.054\n",
      "epoch_nr: 64, train_loss: 0.986, test_loss: 1.058\n",
      "epoch_nr: 65, train_loss: 0.985, test_loss: 1.058\n",
      "epoch_nr: 66, train_loss: 0.985, test_loss: 1.059\n",
      "epoch_nr: 67, train_loss: 0.984, test_loss: 1.065\n",
      "epoch_nr: 68, train_loss: 0.983, test_loss: 1.059\n",
      "epoch_nr: 69, train_loss: 0.983, test_loss: 1.059\n",
      "epoch_nr: 70, train_loss: 0.983, test_loss: 1.060\n",
      "epoch_nr: 71, train_loss: 0.982, test_loss: 1.061\n",
      "epoch_nr: 72, train_loss: 0.982, test_loss: 1.060\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-fe30532c6388>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     80\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch_nr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_batches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loss_op\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m         \u001b[0mtrain_loss\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0mloss_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    898\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 900\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    901\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1133\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1135\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1136\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1314\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1315\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1316\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1317\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1320\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1324\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1305\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1306\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1307\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1309\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1407\u001b[0m       return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1408\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1409\u001b[0;31m           run_metadata)\n\u001b[0m\u001b[1;32m   1410\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1411\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_exception_on_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from matrix_helpers import load_data, write_submission_file\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from DAE import DAE\n",
    "from dataset import _get_training_data, _get_test_data\n",
    "\n",
    "\n",
    "tf.app.flags.DEFINE_string('f', '', 'kernel')\n",
    "# See: https://github.com/tensorflow/tensorflow/issues/17702\n",
    "tf.app.flags.DEFINE_integer('num_epoch', 100,\n",
    "                            'Number of training epochs.')\n",
    "\n",
    "tf.app.flags.DEFINE_integer('batch_size', 125,\n",
    "                            'Size of the training batch.')\n",
    "\n",
    "tf.app.flags.DEFINE_float('learning_rate',0.0005,\n",
    "                          'Learning_Rate')\n",
    "\n",
    "tf.app.flags.DEFINE_boolean('l2_reg', False,\n",
    "                            'L2 regularization.'\n",
    "                            )\n",
    "tf.app.flags.DEFINE_float('lambda_',0.01,\n",
    "                          'Wight decay factor.')\n",
    "\n",
    "tf.app.flags.DEFINE_integer('num_v', 1000,\n",
    "                            'Number of visible neurons (Number of movies the users rated.)')\n",
    "\n",
    "tf.app.flags.DEFINE_integer('num_h', 128,\n",
    "                            'Number of hidden neurons.)')\n",
    "\n",
    "tf.app.flags.DEFINE_integer('num_samples', 10000,\n",
    "                            'Number of training samples (Number of users, who gave a rating).')\n",
    "\n",
    "tf.app.flags.DEFINE_boolean('re_feed', True,\n",
    "                            'Re-feed the results of one pass back into the network.')\n",
    "\n",
    "FLAGS = tf.app.flags.FLAGS\n",
    "\n",
    "'''Building the graph, opening of a session and starting the training od the neural network.'''\n",
    "\n",
    "num_batches=int(FLAGS.num_samples/FLAGS.batch_size)\n",
    "\n",
    "default_graph = tf.Graph().as_default()\n",
    "\n",
    "data_mat = load_data()\n",
    "train_mat, test_mat = train_test_split(data_mat, train_size=0.8)\n",
    "\n",
    "train_data, train_data_infer=_get_training_data(FLAGS, train_mat)\n",
    "test_data=_get_test_data(FLAGS, test_mat)\n",
    "pred_data = _get_test_data(FLAGS, data_mat)\n",
    "\n",
    "iter_train = train_data.make_initializable_iterator()\n",
    "iter_train_infer=train_data_infer.make_initializable_iterator()\n",
    "iter_test = test_data.make_initializable_iterator()\n",
    "iter_pred = pred_data.make_initializable_iterator()\n",
    "\n",
    "x_train = iter_train.get_next()\n",
    "x_train_infer =iter_train_infer.get_next()\n",
    "x_test = iter_test.get_next()\n",
    "x_pred = iter_pred.get_next()\n",
    "\n",
    "model = DAE(FLAGS)\n",
    "\n",
    "train_op, train_loss_op=model._optimizer(x_train)\n",
    "pred_op, test_loss_op=model._validation_loss(x_train_infer, x_test)\n",
    "infer_op = model._inference(x_pred, train_mode=False)\n",
    "\n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "sess.run(tf.global_variables_initializer())\n",
    "train_loss=0\n",
    "test_loss=0\n",
    "\n",
    "for epoch in range(FLAGS.num_epoch):\n",
    "\n",
    "    sess.run(iter_train.initializer)\n",
    "\n",
    "    for batch_nr in range(num_batches):\n",
    "\n",
    "        _, loss_=sess.run((train_op, train_loss_op))\n",
    "        train_loss+=loss_\n",
    "\n",
    "    sess.run(iter_train_infer.initializer)\n",
    "    sess.run(iter_test.initializer)\n",
    "\n",
    "    for i in range(FLAGS.num_samples):\n",
    "        pred, loss_=sess.run((pred_op, test_loss_op))\n",
    "        test_loss+=loss_\n",
    "\n",
    "    print('epoch_nr: %i, train_loss: %.3f, test_loss: %.3f'%(epoch,(train_loss/num_batches),(test_loss/FLAGS.num_samples)))\n",
    "    train_loss=0\n",
    "    test_loss=0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build output matrix (aka run one time again)\n",
    "sess.run(iter_pred.initializer)\n",
    "preds = []\n",
    "for batch_nr in range(FLAGS.num_samples):\n",
    "    pred = sess.run((infer_op))\n",
    "    preds.append(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pred = np.concatenate(tuple(preds), axis=0)\n",
    "X_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_submission_file(X_pred, 'submission_autoencoder_0.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

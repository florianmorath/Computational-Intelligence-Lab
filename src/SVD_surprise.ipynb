{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVD baseline algorithm using surprise package:\n",
    "\n",
    "using `matrix_factorization.SVD` algorithm from http://surprise.readthedocs.io/en/stable/prediction_algorithms_package.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### [KBV09] Yehuda Koren. Matrix factorization techniques for recommender systems.\n",
    "\n",
    "see [Matrix Factorization techniques](https://datajobs.com/data-science-repo/Recommender-Systems-[Netflix].pdf)\n",
    "\n",
    "explicit feedback = (user,item, rating) represented as user-item matrix.\n",
    "\n",
    "Matrix factorization models map both users and items to a joint latent factor space of dimensionality f, such that user-item interactions are modeled as inner products in that space.\n",
    "\n",
    "Assume $r_{ui} = q_i^Tp_u$, how to compute $q_i, p_u$?\n",
    "\n",
    "Want to minimize $min_{p_u, q_i} \\sum_{x_{ui}}(r_{ui}-p_u^Tq_i)^2 + \\lambda ($$ \\lVert q_i \\rVert $$^2 + $$ \\lVert p_u \\rVert $$^2)$\n",
    "\n",
    "1. Can use SGD to optimize (see Simon Funk) <- focus here\n",
    "2. Can use ALS (convexifies the objective)\n",
    "\n",
    "__Adding Biases__:\n",
    "some users tend to give higher/lower ratings then others. And some items tend to receive higher/lower ratings than others (relatively seen).\n",
    "\n",
    "Bias involved in rating $r_{ui}$ is denoted by $b_{ui}$:<br/>\n",
    "$b_{ui} = \\mu + b_i + b_u$ <br/>\n",
    "$\\mu$: average rating over all movies <br/>\n",
    "$b_i$: deviation of item i from average <br/>\n",
    "$b_u$: deviation of user u from average <br/>\n",
    "\n",
    "estimate of rating is: <br/>\n",
    "$r_{ui} = \\mu + b_i + b_u + q_i^Tp_u$\n",
    "\n",
    "adjusted objective: <br/>\n",
    " $min_{p_u, q_i} \\sum_{x_{ui}}(r_{ui}-\\mu-b_u-b_i -p_u^Tq_i)^2 + \\lambda ($$ \\lVert q_i \\rVert $$^2 + $$ \\lVert p_u \\rVert $$^2 + b_u^2 + b_i^2)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "import helpers\n",
    "from surprise_helpers import CustomReader, get_ratings_from_predictions\n",
    "from surprise import Reader, Dataset\n",
    "from surprise.model_selection.search import RandomizedSearchCV\n",
    "from surprise.prediction_algorithms.matrix_factorization import SVD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = CustomReader()\n",
    "filepath = helpers.get_train_file_path()\n",
    "data = Dataset.load_from_file(filepath, reader=reader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search over params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'n_epochs': stats.randint(5,20), \n",
    "              'lr_all': stats.uniform(0.002,0.005),\n",
    "              'reg_all': stats.uniform(0.02,0.6),\n",
    "              'n_factors': stats.randint(50,150),\n",
    "             }      \n",
    "        \n",
    "\n",
    "gs = RandomizedSearchCV(algo_class=SVD, param_distributions=param_grid, measures=['rmse'], \n",
    "                        cv=10, joblib_verbose=100, n_jobs=-1, n_iter=100)\n",
    "gs.fit(data)\n",
    "\n",
    "# best RMSE score\n",
    "print(gs.best_score['rmse'])\n",
    "\n",
    "# combination of parameters that gave the best RMSE score\n",
    "print(gs.best_params['rmse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame.from_dict(gs.cv_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results: params \n",
    "\n",
    "note: run on Leonhard cluster (20 cores and 22GB mem)\n",
    "cv=10\n",
    "\n",
    "0.996617863993\n",
    "{'lr_all': 0.0080655611939959484, 'n_epochs': 19, 'n_factors': 9, 'reg_all': 0.042201220509606799}\n",
    "\n",
    "0.998777808857\n",
    "{'n_factors': 5}\n",
    "\n",
    "1.00085021593\n",
    "{'lr_all': 0.0035314408264436933, 'n_epochs': 19, 'n_factors': 50, 'reg_all': 0.027105037999075404}\n",
    "\n",
    "1.00534587695\n",
    "{'lr_all': 0.0034656840329879137, 'n_epochs': 10, 'n_factors': 42, 'reg_all': 0.12231592623013628}\n",
    "\n",
    "1.00104676332\n",
    "{'lr_all': 0.0066032381482039656, 'n_epochs': 17, 'n_factors': 107, 'reg_all': 0.036362623151074552}\n",
    "\n",
    "1.00382744957\n",
    "{'lr_all': 0.0045664408289589759, 'n_epochs': 12, 'n_factors': 9, 'reg_all': 0.04029560227746723}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<surprise.prediction_algorithms.matrix_factorization.SVD at 0x10f07c128>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# choose optimal params from above\n",
    "#algo = SVD(n_epochs=19, lr_all=0.0080655611939959484, reg_all=0.042201220509606799, n_factors=9)\n",
    "algo = SVD( n_factors=5)\n",
    "\n",
    "# train \n",
    "algo.fit(data.build_full_trainset())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting\n",
    "We load the test data to predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Prediction(uid=36, iid=0, r_ui=3.0, est=3.175193448906952, details={'was_impossible': False})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_file_path = helpers.get_test_file_path()\n",
    "test_data = Dataset.load_from_file(test_file_path, reader=reader)\n",
    "testset = test_data.construct_testset(test_data.raw_ratings)\n",
    "predictions = algo.test(testset)\n",
    "predictions[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to convert the predictions into the right format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = get_ratings_from_predictions(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can write the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Id,Prediction\n",
      "r37_c1,3.175193\n",
      "r73_c1,3.022989\n",
      "r156_c1,3.743569\n",
      "r160_c1,3.393022\n",
      "r248_c1,3.336667\n",
      "r25\n"
     ]
    }
   ],
   "source": [
    "output = helpers.write_submission(ratings, 'submission_surprise_SVD_1.csv')\n",
    "print(output[0:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

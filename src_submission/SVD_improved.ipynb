{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVD improved algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Theory behind\n",
    "\n",
    "### [KBV09] Yehuda Koren. Matrix factorization techniques for recommender systems.\n",
    "\n",
    "see [Matrix Factorization techniques](https://datajobs.com/data-science-repo/Recommender-Systems-[Netflix].pdf)\n",
    "\n",
    "explicit feedback = (user,item, rating) represented as user-item matrix.\n",
    "\n",
    "Matrix factorization models map both users and items to a joint latent factor space of dimensionality f, such that user-item interactions are modeled as inner products in that space.\n",
    "\n",
    "Assume $r_{ui} = q_i^Tp_u$, how to compute $q_i, p_u$?\n",
    "\n",
    "Want to minimize $min_{p_u, q_i} \\sum_{x_{ui}}(r_{ui}-p_u^Tq_i)^2 + \\lambda ($$ \\lVert q_i \\rVert $$^2 + $$ \\lVert p_u \\rVert $$^2)$\n",
    "\n",
    "1. Can use SGD to optimize (see Simon Funk) <- focus here\n",
    "2. Can use ALS (convexifies the objective)\n",
    "\n",
    "__Adding Biases__:\n",
    "some users tend to give higher/lower ratings then others. And some items tend to receive higher/lower ratings than others (relatively seen).\n",
    "\n",
    "Bias involved in rating $r_{ui}$ is denoted by $b_{ui}$:<br/>\n",
    "$b_{ui} = \\mu + b_i + b_u$ <br/>\n",
    "$\\mu$: average rating over all movies <br/>\n",
    "$b_i$: deviation of item i from average <br/>\n",
    "$b_u$: deviation of user u from average <br/>\n",
    "\n",
    "estimate of rating is: <br/>\n",
    "$r_{ui} = \\mu + b_i + b_u + q_i^Tp_u$\n",
    "\n",
    "adjusted objective: <br/>\n",
    " $min_{p_u, q_i} \\sum_{x_{ui}}(r_{ui}-\\mu-b_u-b_i -p_u^Tq_i)^2 + \\lambda ($$ \\lVert q_i \\rVert $$^2 + $$ \\lVert p_u \\rVert $$^2 + b_u^2 + b_i^2)$\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numbers\n",
    "\n",
    "from scipy import stats\n",
    "from six.moves import range\n",
    "from __future__ import (absolute_import, division, print_function, unicode_literals)\n",
    "\n",
    "from surprise_extensions import CustomReader, get_ratings_from_predictions\n",
    "from surprise import Reader, Dataset\n",
    "from surprise.model_selection.search import RandomizedSearchCV\n",
    "from surprise import AlgoBase\n",
    "\n",
    "import data_handler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVD algorithm implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The SVD algorithm was popularized by Simon Funk in his blog called [Netflix Update: Try this at home](http://sifter.org/simon/journal/20061211.html). The theory behind it, also described in the paper \"Matrix factorization techniques for recommender systems\" by Yehuda Koren, is summarized above.\n",
    "\n",
    "Note: The code below is a modification/extension of the SVD implementation in the Surprise package http://surprise.readthedocs.io/en/stable/matrix_factorization.html#surprise.prediction_algorithms.matrix_factorization.SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rng(random_state):\n",
    "        '''Return a 'validated' RNG. If random_state is None, use RandomState singleton from numpy.  Else if\n",
    "        it's an integer, consider it's a seed and initialized an rng with that seed. If it's already an rng, return it.\n",
    "        '''\n",
    "        if random_state is None:\n",
    "            return np.random.mtrand._rand\n",
    "        elif isinstance(random_state, (numbers.Integral, np.integer)):\n",
    "            return np.random.RandomState(random_state)\n",
    "        if isinstance(random_state, np.random.RandomState):\n",
    "            return random_state\n",
    "        raise ValueError('Wrong random state. Expecting None, an int or a numpy '\n",
    "                         'RandomState instance, got a '\n",
    "                         '{}'.format(type(random_state)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SVD(AlgoBase):\n",
    "    \"\"\"The famous *SVD* algorithm, as popularized by Simon Funk.\n",
    "    \n",
    "    Args:\n",
    "        n_factors: The number of factors. Default is ``100``.\n",
    "        n_epochs: The number of iteration of the SGD procedure. Default is ``20``.\n",
    "        biased(bool): Whether to use baselines (or biases). Default is ``True``.\n",
    "        init_mean: The mean of the normal distribution for factor vectors initialization. Default is ``0``.\n",
    "        init_std_dev: The standard deviation of the normal distribution for factor vectors initialization. Default is ``0.1``.\n",
    "        lr_all: The learning rate for all parameters. Default is ``0.005``.\n",
    "        reg_all: The regularization term for all parameters. Default is ``0.02``.\n",
    "        random_state(int, RandomState instance from numpy, or ``None``):\n",
    "            Determines the RNG that will be used for initialization. If int, ``random_state`` will be used as a seed for a new RNG. \n",
    "            This is useful to get the same initialization over multiple calls to ``fit()``.  \n",
    "            If RandomState instance, this same instance is used as RNG. If ``None``, the current RNG from numpy is used.  \n",
    "            Default is ``None``.\n",
    "        verbose: If ``True``, prints the current epoch. Default is ``False``.\n",
    "        \n",
    "    Attributes:\n",
    "        pu(numpy array of size (n_users, n_factors)): The user factors (only exists if ``fit()`` has been called)\n",
    "        qi(numpy array of size (n_items, n_factors)): The item factors (only exists if ``fit()`` has been called)\n",
    "        bu(numpy array of size (n_users)): The user biases (only exists if ``fit()`` has been called)\n",
    "        bi(numpy array of size (n_items)): The item biases (only exists if ``fit()`` has been called)\n",
    "        train_error(list of size (n_epochs)): List of training errors per epoch.\n",
    "    \"\"\"\n",
    "   \n",
    "    def __init__(self, n_factors=100, n_epochs=20, biased=True, init_mean=0, init_std_dev=.1, lr_all=.005, reg_all=.02, \n",
    "                 lr_bu=None, lr_bi=None, lr_pu=None, lr_qi=None, reg_bu=None, reg_bi=None, reg_pu=None, reg_qi=None,\n",
    "                 random_state=None, verbose=False):\n",
    "\n",
    "        self.n_factors = n_factors\n",
    "        self.n_epochs = n_epochs\n",
    "        self.biased = biased\n",
    "        self.init_mean = init_mean\n",
    "        self.init_std_dev = init_std_dev\n",
    "        self.lr_bu = lr_bu if lr_bu is not None else lr_all\n",
    "        self.lr_bi = lr_bi if lr_bi is not None else lr_all\n",
    "        self.lr_pu = lr_pu if lr_pu is not None else lr_all\n",
    "        self.lr_qi = lr_qi if lr_qi is not None else lr_all\n",
    "        self.reg_bu = reg_bu if reg_bu is not None else reg_all\n",
    "        self.reg_bi = reg_bi if reg_bi is not None else reg_all\n",
    "        self.reg_pu = reg_pu if reg_pu is not None else reg_all\n",
    "        self.reg_qi = reg_qi if reg_qi is not None else reg_all\n",
    "        self.random_state = random_state\n",
    "        self.verbose = verbose\n",
    "        self.train_error = [] # list of train error per epoch\n",
    "\n",
    "        AlgoBase.__init__(self)\n",
    "\n",
    "    def fit(self, trainset):\n",
    "        \"\"\"Fit the model parameters to the training set.\n",
    "        \n",
    "        Args:\n",
    "            trainset(Trainset): The training set which is used to fit the model.\n",
    "        \n",
    "        \"\"\"\n",
    "    \n",
    "        AlgoBase.fit(self, trainset)\n",
    "        self.sgd(trainset)\n",
    "\n",
    "        return self\n",
    "    \n",
    "    def sgd(self, trainset):\n",
    "        \"\"\"This method is called by the fit method and performs the sgd steps which update the parameters.\n",
    "         \n",
    "        Args:\n",
    "            trainset(Trainset): The training set which is used to fit the model.\n",
    "        \"\"\"\n",
    "        \n",
    "        global_mean = self.trainset.global_mean\n",
    "\n",
    "        # local variables ofer some performance advantage over class member attributes.\n",
    "        lr_bu = self.lr_bu\n",
    "        lr_bi = self.lr_bi\n",
    "        lr_pu = self.lr_pu\n",
    "        lr_qi = self.lr_qi\n",
    "\n",
    "        reg_bu = self.reg_bu\n",
    "        reg_bi = self.reg_bi\n",
    "        reg_pu = self.reg_pu\n",
    "        reg_qi = self.reg_qi\n",
    "\n",
    "        rng = get_rng(self.random_state)\n",
    "\n",
    "        bu = np.zeros(trainset.n_users, np.double)\n",
    "        bi = np.zeros(trainset.n_items, np.double)\n",
    "        pu = rng.normal(self.init_mean, self.init_std_dev,\n",
    "                        (trainset.n_users, self.n_factors))\n",
    "        qi = rng.normal(self.init_mean, self.init_std_dev,\n",
    "                        (trainset.n_items, self.n_factors))\n",
    "\n",
    "        if not self.biased:\n",
    "            global_mean = 0\n",
    "\n",
    "        for current_epoch in range(self.n_epochs):\n",
    "            if self.verbose:\n",
    "                print(\"Processing epoch {}\".format(current_epoch))\n",
    "            train_error = 0\n",
    "            for u, i, r in trainset.all_ratings():\n",
    "\n",
    "                # compute current error\n",
    "                dot = 0  # <q_i, p_u>\n",
    "                for f in range(self.n_factors):\n",
    "                    dot += qi[i, f] * pu[u, f]\n",
    "                err = r - (global_mean + bu[u] + bi[i] + dot)\n",
    "                train_error += abs(err)\n",
    "\n",
    "                # update biases\n",
    "                if self.biased:\n",
    "                    bu[u] += lr_bu * (err - reg_bu * bu[u])\n",
    "                    bi[i] += lr_bi * (err - reg_bi * bi[i])\n",
    "\n",
    "                # update factors\n",
    "                for f in range(self.n_factors):\n",
    "                    puf = pu[u, f]\n",
    "                    qif = qi[i, f]\n",
    "                    pu[u, f] += lr_pu * (err * qif - reg_pu * puf)\n",
    "                    qi[i, f] += lr_qi * (err * puf - reg_qi * qif)\n",
    "                    \n",
    "            self.train_error.append(train_error)\n",
    "\n",
    "        self.bu = bu\n",
    "        self.bi = bi\n",
    "        self.pu = pu\n",
    "        self.qi = qi\n",
    "\n",
    "    def estimate(self, u, i):\n",
    "        \"\"\"Predict rating of user u and movie i.\n",
    "        \n",
    "        Args:\n",
    "            u(int): user id\n",
    "            i(int): movie id\n",
    "        \n",
    "        Returns:\n",
    "            float: the predicted rating of user u and movie i. \n",
    "        \"\"\"\n",
    "\n",
    "        known_user = self.trainset.knows_user(u)\n",
    "        known_item = self.trainset.knows_item(i)\n",
    "\n",
    "        if self.biased:\n",
    "            est = self.trainset.global_mean\n",
    "\n",
    "            if known_user:\n",
    "                est += self.bu[u]\n",
    "\n",
    "            if known_item:\n",
    "                est += self.bi[i]\n",
    "\n",
    "            if known_user and known_item:\n",
    "                est += np.dot(self.qi[i], self.pu[u])\n",
    "\n",
    "        else:\n",
    "            if known_user and known_item:\n",
    "                est = np.dot(self.qi[i], self.pu[u])\n",
    "            else:\n",
    "                raise Exception('User and item are unkown.')\n",
    "\n",
    "        return est\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = CustomReader()\n",
    "filepath = data_handler.get_train_file_path()\n",
    "data = Dataset.load_from_file(filepath, reader=reader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {  'n_factors': stats.randint(150,160),\n",
    "                'lr_bu': stats.uniform(0.004,0.007),\n",
    "                'lr_bi': stats.uniform(0.004,0.007),\n",
    "                'lr_qi': stats.uniform(0.01,0.03),\n",
    "                'lr_pu': stats.uniform(0.01,0.03),\n",
    "                'reg_bi': stats.uniform(0.02,0.05),\n",
    "                'reg_bu': stats.uniform(0.04,0.06),\n",
    "                'reg_qi': stats.uniform(0.04,0.08),\n",
    "                'reg_pu': stats.uniform(0.02,0.2),\n",
    "                'init_std_dev': stats.uniform(0.01,0.8),\n",
    "                'n_epochs': stats.randint(10,30)\n",
    "             }         \n",
    "        \n",
    "# do cross validation to find the bast hyper parameters\n",
    "gs = RandomizedSearchCV(algo_class=SVD, param_distributions=param_grid, measures=['rmse'], \n",
    "                        cv=10, joblib_verbose=100, n_jobs=-1, n_iter=100)\n",
    "gs.fit(data)\n",
    "\n",
    "# best RMSE score\n",
    "print(gs.best_score['rmse'])\n",
    "\n",
    "# combination of parameters that gave the best RMSE score\n",
    "print(gs.best_params['rmse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame.from_dict(gs.cv_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RMSE results for different parameters\n",
    "\n",
    "Cross-validation over 10 folds.\n",
    "Run on Leonhard cluster (20 cores and 22GB mem)\n",
    "\n",
    "\n",
    "0.98460820897\n",
    "{'lr_bi': 0.0045699937900061235, 'lr_bu': 0.0053470080935120153, 'lr_pu': 0.017294772891100464, 'lr_qi': 0.016495757165001537, 'n_epochs': 26, 'n_factors': 159, 'reg_bi': 0.026026359248845211, 'reg_bu': 0.099924883620357285, 'reg_pu': 0.10778441193893745, 'reg_qi': 0.071670616244315685}\n",
    "\n",
    "0.98489843593\n",
    "{'lr_bi': 0.0043688979424132048, 'lr_bu': 0.005613464182452876, 'lr_pu': 0.022148955075059311, 'lr_qi': 0.012530626289208299, 'n_factors': 151, 'reg_bi': 0.042342905803236859, 'reg_bu': 0.073415041823889998, 'reg_pu': 0.12513844856777867, 'reg_qi': 0.060228735604464054}\n",
    "\n",
    "0.984953534195\n",
    "{'lr_bi': 0.0040080904244357771, 'lr_bu': 0.0083752718099860367, 'lr_pu': 0.010813216008005243, 'lr_qi': 0.018992188100229335, 'n_factors': 158, 'reg_bi': 0.02384386240305832, 'reg_bu': 0.087957272220067495, 'reg_pu': 0.17370665665508969, 'reg_qi': 0.042977558957037719}\n",
    "\n",
    "0.985070495179\n",
    "{'init_std_dev': 0.031184006269592716, 'lr_bi': 0.0048978641284463517, 'lr_bu': 0.010989040837895429, 'lr_pu': 0.016034035470675671, 'lr_qi': 0.012197663818154646, 'n_factors': 151, 'reg_bi': 0.029524162229769623, 'reg_bu': 0.042540872922616352, 'reg_pu': 0.071567945780504169, 'reg_qi': 0.075092708208885889}\n",
    "\n",
    "0.9853091859177997\n",
    "{'lr_bi': 0.0050565201838808, 'lr_bu': 0.005529901817482, 'lr_pu': 0.021009781711363945, 'lr_qi': 0.019237920706921686, 'n_factors': 153, 'reg_bi': 0.027507293418947705, 'reg_bu': 0.04792231303919493, 'reg_pu': 0.1051659555261933, 'reg_qi': 0.05739791764348274}\n",
    "\n",
    "0.985423383238\n",
    "{'lr_bi': 0.0045872175952940859, 'lr_bu': 0.0059198576112051132, 'lr_pu': 0.03996299827445985, 'lr_qi': 0.012744793911701359, 'n_factors': 156, 'reg_bi': 0.039006956026578499, 'reg_bu': 0.058835165460011773, 'reg_pu': 0.065999449644116956, 'reg_qi': 0.11943136846519176}\n",
    "\n",
    "0.98576635754\n",
    "{'lr_bi': 0.004388787077144584, 'lr_bu': 0.0077070689204476878, 'lr_pu': 0.037207361664974598, 'lr_qi': 0.011526606878613951, 'n_factors': 155, 'reg_bi': 0.055491394820528769, 'reg_bu': 0.025510174666992846, 'reg_pu': 0.073005652506841268, 'reg_qi': 0.084369830119022798}\n",
    "\n",
    "0.985920828862\n",
    "{'lr_bi': 0.0061067123779277675, 'lr_bu': 0.005972391928230663, 'lr_pu': 0.023802281518036983, 'lr_qi': 0.016117532546202691, 'n_factors': 157, 'reg_bi': 0.013775300394299965, 'reg_bu': 0.034301808303089626, 'reg_pu': 0.09627118462747386, 'reg_qi': 0.061245371260615522}\n",
    "\n",
    "0.986355638337\n",
    "{'lr_bi': 0.0053921528073649578, 'lr_bu': 0.014983628487378223, 'lr_pu': 0.025070307435290061, 'lr_qi': 0.0073965320227803123, 'n_factors': 154, 'reg_bi': 0.027365169456015866, 'reg_bu': 0.03585534141987403, 'reg_pu': 0.15019357711020351, 'reg_qi': 0.050166823853083298}\n",
    "\n",
    "0.986851655568\n",
    "{'lr_bi': 0.0053647824382532638, 'lr_bu': 0.0052769550628727633, 'lr_pu': 0.012545946659482476, 'lr_qi': 0.012795461232426109, 'n_factors': 156, 'reg_bi': 0.056418600300998704, 'reg_bu': 0.022556567389521144, 'reg_pu': 0.061086848339968164, 'reg_qi': 0.077168605512323629}\n",
    "\n",
    "0.9872175653005135\n",
    "{'lr_bi': 0.006088703690766571, 'lr_bu': 0.012744554096322995, 'lr_pu': 0.012380073174962966, 'lr_qi': 0.009130873179651982, 'n_factors': 158, 'reg_bi': 0.012919509150189782, 'reg_bu': 0.036795609500178635, 'reg_pu': 0.10361453028270178, 'reg_qi': 0.048785998289016745}\n",
    "\n",
    "0.988058743973\n",
    "{'lr_bi': 0.0045634712043475644, 'lr_bu': 0.01064562075669161, 'lr_pu': 0.012470219046795966, 'lr_qi': 0.0069239309430058314, 'n_factors': 160, 'reg_bi': 0.038064835563680136, 'reg_bu': 0.083204917488220814, 'reg_pu': 0.044129727640422105, 'reg_qi': 0.083532754108250978}\n",
    "\n",
    "0.9882588317180945\n",
    "{'lr_bi': 0.005572132295112126, 'lr_bu': 0.010459976354655289, 'lr_pu': 0.012621031473530591, 'lr_qi': 0.009189138000229718, 'n_factors': 81, 'reg_bi': 0.09508515857935072, 'reg_bu': 0.08100593615106191, 'reg_pu': 0.08560885565821767, 'reg_qi': 0.06136778252645429}\n",
    "\n",
    "0.9889400786056195\n",
    "{'lr_bi': 0.00505521532063321, 'lr_bu': 0.012181115620042492, 'lr_pu': 0.0094679873549249, 'lr_qi': 0.00612337262019204, 'n_factors': 108, 'reg_bi': 0.023237810934149287, 'reg_bu': 0.09931980200620626, 'reg_pu': 0.07865295413390713, 'reg_qi': 0.04964170302513018}\n",
    "\n",
    "0.9894911251394463\n",
    "{'lr_bi': 0.006439713022658003, 'lr_bu': 0.005220730820427025, 'lr_pu': 0.012121360196274768, 'lr_qi': 0.010296116770652414, 'n_factors': 98, 'reg_bi': 0.07326008897853639, 'reg_bu': 0.0654521219387276, 'reg_pu': 0.07673672028564435, 'reg_qi': 0.07732908168371602}\n",
    "\n",
    "0.992159817137\n",
    "{'lr_all': 0.0088540357639887227, 'n_factors': 94, 'reg_all': 0.060980144283391415}\n",
    "\n",
    "0.9922037152942101\n",
    "{'lr_all': 0.009404839806784696, 'n_factors': 83, 'reg_all': 0.06361145065359476}\n",
    "\n",
    "0.9923411994233705\n",
    "{'lr_all': 0.009518436883800755, 'n_factors': 98, 'reg_all': 0.06448898038350545}\n",
    "\n",
    "0.996356760492\n",
    "{'lr_all': 0.0069735838056049675, 'n_factors': 16, 'reg_all': 0.040538641816816053}\n",
    "\n",
    "0.996617863993\n",
    "{'lr_all': 0.0080655611939959484, 'n_epochs': 19, 'n_factors': 9, 'reg_all': 0.042201220509606799}\n",
    "\n",
    "0.996918766638\n",
    "{'lr_all': 0.010438622204618025, 'n_factors': 16, 'reg_all': 0.069969144045048129}\n",
    "\n",
    "0.998777808857\n",
    "{'n_factors': 5}\n",
    "\n",
    "0.999721712849\n",
    "{'lr_all': 0.0048483945439183485, 'n_factors': 9}\n",
    "\n",
    "1.00085021593\n",
    "{'lr_all': 0.0035314408264436933, 'n_epochs': 19, 'n_factors': 50, 'reg_all': 0.027105037999075404}\n",
    "\n",
    "1.00534587695\n",
    "{'lr_all': 0.0034656840329879137, 'n_epochs': 10, 'n_factors': 42, 'reg_all': 0.12231592623013628}\n",
    "\n",
    "1.00104676332\n",
    "{'lr_all': 0.0066032381482039656, 'n_epochs': 17, 'n_factors': 107, 'reg_all': 0.036362623151074552}\n",
    "\n",
    "1.00382744957\n",
    "{'lr_all': 0.0045664408289589759, 'n_epochs': 12, 'n_factors': 9, 'reg_all': 0.04029560227746723}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.SVD at 0x134864080>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# choose optimal params from above\n",
    "n_epochs = 26\n",
    "algo = SVD(n_factors=159, lr_bi=0.0045699937900061235, lr_bu=0.0053470080935120153, lr_pu=0.017294772891100464, lr_qi=0.016495757165001537, reg_bi=0.026026359248845211, reg_bu=0.099924883620357285, reg_pu=0.10778441193893745, reg_qi=0.071670616244315685, n_epochs=n_epochs)\n",
    "\n",
    "# train the algorithm\n",
    "algo.fit(data.build_full_trainset())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot error over epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(1,n_epochs+1), algo.train_error, 'r--')\n",
    "plt.legend(['Training Loss'])\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting\n",
    "We load the test data to predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_file_path = data_handler.get_test_file_path()\n",
    "test_data = Dataset.load_from_file(test_file_path, reader=reader)\n",
    "testset = test_data.construct_testset(test_data.raw_ratings)\n",
    "predictions = algo.test(testset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to convert the predictions into the right format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = get_ratings_from_predictions(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can write the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = data_handler.write_submission(ratings, 'submission_surprise_SVD_5.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

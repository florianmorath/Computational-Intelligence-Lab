{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVD improved algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### [KBV09] Yehuda Koren. Matrix factorization techniques for recommender systems.\n",
    "\n",
    "see [Matrix Factorization techniques](https://datajobs.com/data-science-repo/Recommender-Systems-[Netflix].pdf)\n",
    "\n",
    "explicit feedback = (user,item, rating) represented as user-item matrix.\n",
    "\n",
    "Matrix factorization models map both users and items to a joint latent factor space of dimensionality f, such that user-item interactions are modeled as inner products in that space.\n",
    "\n",
    "Assume $r_{ui} = q_i^Tp_u$, how to compute $q_i, p_u$?\n",
    "\n",
    "Want to minimize $min_{p_u, q_i} \\sum_{x_{ui}}(r_{ui}-p_u^Tq_i)^2 + \\lambda ($$ \\lVert q_i \\rVert $$^2 + $$ \\lVert p_u \\rVert $$^2)$\n",
    "\n",
    "1. Can use SGD to optimize (see Simon Funk) <- focus here\n",
    "2. Can use ALS (convexifies the objective)\n",
    "\n",
    "__Adding Biases__:\n",
    "some users tend to give higher/lower ratings then others. And some items tend to receive higher/lower ratings than others (relatively seen).\n",
    "\n",
    "Bias involved in rating $r_{ui}$ is denoted by $b_{ui}$:<br/>\n",
    "$b_{ui} = \\mu + b_i + b_u$ <br/>\n",
    "$\\mu$: average rating over all movies <br/>\n",
    "$b_i$: deviation of item i from average <br/>\n",
    "$b_u$: deviation of user u from average <br/>\n",
    "\n",
    "estimate of rating is: <br/>\n",
    "$r_{ui} = \\mu + b_i + b_u + q_i^Tp_u$\n",
    "\n",
    "adjusted objective: <br/>\n",
    " $min_{p_u, q_i} \\sum_{x_{ui}}(r_{ui}-\\mu-b_u-b_i -p_u^Tq_i)^2 + \\lambda ($$ \\lVert q_i \\rVert $$^2 + $$ \\lVert p_u \\rVert $$^2 + b_u^2 + b_i^2)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numbers\n",
    "\n",
    "from scipy import stats\n",
    "from six.moves import range\n",
    "from __future__ import (absolute_import, division, print_function, unicode_literals)\n",
    "\n",
    "from surprise_helpers import CustomReader, get_ratings_from_predictions\n",
    "from surprise import Reader, Dataset\n",
    "from surprise.model_selection.search import RandomizedSearchCV\n",
    "from surprise import AlgoBase\n",
    "\n",
    "import helpers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVD algorithm implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The SVD algorithm was popularized by Simon Funk in his blog called [Netflix Update: Try this at home](http://sifter.org/simon/journal/20061211.html). The theory behind it, also described in the paper \"Matrix factorization techniques for recommender systems\" by Yehuda Koren, is summarized above.\n",
    "\n",
    "Note: The code below is a modification/extension of the SVD implementation in the Surprise package http://surprise.readthedocs.io/en/stable/matrix_factorization.html#surprise.prediction_algorithms.matrix_factorization.SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rng(random_state):\n",
    "        '''Return a 'validated' RNG. If random_state is None, use RandomState singleton from numpy.  Else if\n",
    "        it's an integer, consider it's a seed and initialized an rng with that seed. If it's already an rng, return it.\n",
    "        '''\n",
    "        if random_state is None:\n",
    "            return np.random.mtrand._rand\n",
    "        elif isinstance(random_state, (numbers.Integral, np.integer)):\n",
    "            return np.random.RandomState(random_state)\n",
    "        if isinstance(random_state, np.random.RandomState):\n",
    "            return random_state\n",
    "        raise ValueError('Wrong random state. Expecting None, an int or a numpy '\n",
    "                         'RandomState instance, got a '\n",
    "                         '{}'.format(type(random_state)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SVD(AlgoBase):\n",
    "    \"\"\"The famous *SVD* algorithm, as popularized by Simon Funk.\n",
    "    \n",
    "    Args:\n",
    "        n_factors: The number of factors. Default is ``100``.\n",
    "        n_epochs: The number of iteration of the SGD procedure. Default is ``20``.\n",
    "        biased(bool): Whether to use baselines (or biases). Default is ``True``.\n",
    "        init_mean: The mean of the normal distribution for factor vectors initialization. Default is ``0``.\n",
    "        init_std_dev: The standard deviation of the normal distribution for factor vectors initialization. Default is ``0.1``.\n",
    "        lr_all: The learning rate for all parameters. Default is ``0.005``.\n",
    "        reg_all: The regularization term for all parameters. Default is ``0.02``.\n",
    "        random_state(int, RandomState instance from numpy, or ``None``):\n",
    "            Determines the RNG that will be used for initialization. If int, ``random_state`` will be used as a seed for a new RNG. \n",
    "            This is useful to get the same initialization over multiple calls to ``fit()``.  \n",
    "            If RandomState instance, this same instance is used as RNG. If ``None``, the current RNG from numpy is used.  \n",
    "            Default is ``None``.\n",
    "        verbose: If ``True``, prints the current epoch. Default is ``False``.\n",
    "        \n",
    "    Attributes:\n",
    "        pu(numpy array of size (n_users, n_factors)): The user factors (only exists if ``fit()`` has been called)\n",
    "        qi(numpy array of size (n_items, n_factors)): The item factors (only exists if ``fit()`` has been called)\n",
    "        bu(numpy array of size (n_users)): The user biases (only exists if ``fit()`` has been called)\n",
    "        bi(numpy array of size (n_items)): The item biases (only exists if ``fit()`` has been called)\n",
    "        train_error(list of size (n_epochs)): List of training errors per epoch.\n",
    "    \"\"\"\n",
    "   \n",
    "    def __init__(self, n_factors=100, n_epochs=20, biased=True, init_mean=0, init_std_dev=.1, lr_all=.005, reg_all=.02, \n",
    "                 lr_bu=None, lr_bi=None, lr_pu=None, lr_qi=None, reg_bu=None, reg_bi=None, reg_pu=None, reg_qi=None,\n",
    "                 random_state=None, verbose=False):\n",
    "\n",
    "        self.n_factors = n_factors\n",
    "        self.n_epochs = n_epochs\n",
    "        self.biased = biased\n",
    "        self.init_mean = init_mean\n",
    "        self.init_std_dev = init_std_dev\n",
    "        self.lr_bu = lr_bu if lr_bu is not None else lr_all\n",
    "        self.lr_bi = lr_bi if lr_bi is not None else lr_all\n",
    "        self.lr_pu = lr_pu if lr_pu is not None else lr_all\n",
    "        self.lr_qi = lr_qi if lr_qi is not None else lr_all\n",
    "        self.reg_bu = reg_bu if reg_bu is not None else reg_all\n",
    "        self.reg_bi = reg_bi if reg_bi is not None else reg_all\n",
    "        self.reg_pu = reg_pu if reg_pu is not None else reg_all\n",
    "        self.reg_qi = reg_qi if reg_qi is not None else reg_all\n",
    "        self.random_state = random_state\n",
    "        self.verbose = verbose\n",
    "        self.train_error = [] # list of train error per epoch\n",
    "        self.test_error = [] # list of test error per epoch (if self.validation_split is set)\n",
    "\n",
    "        AlgoBase.__init__(self)\n",
    "\n",
    "    def fit(self, trainset):\n",
    "        \"\"\"Fit the model parameters to the training set.\n",
    "        \n",
    "        Args:\n",
    "            trainset(Dataset): The training set which is used to fit the model.\n",
    "        \n",
    "        \"\"\"\n",
    "    \n",
    "        AlgoBase.fit(self, trainset)\n",
    "        self.sgd(trainset)\n",
    "\n",
    "        return self\n",
    "    \n",
    "    def sgd(self, trainset):\n",
    "        \"\"\"This method is called by the fit method and performs the sgd steps which update the parameters.\n",
    "         \n",
    "        Args:\n",
    "            trainset(Dataset): The training set which is used to fit the model.\n",
    "        \"\"\"\n",
    "\n",
    "        global_mean = self.trainset.global_mean\n",
    "\n",
    "        # local variables ofer some performance advantage over class member attributes.\n",
    "        lr_bu = self.lr_bu\n",
    "        lr_bi = self.lr_bi\n",
    "        lr_pu = self.lr_pu\n",
    "        lr_qi = self.lr_qi\n",
    "\n",
    "        reg_bu = self.reg_bu\n",
    "        reg_bi = self.reg_bi\n",
    "        reg_pu = self.reg_pu\n",
    "        reg_qi = self.reg_qi\n",
    "\n",
    "        rng = get_rng(self.random_state)\n",
    "\n",
    "        bu = np.zeros(trainset.n_users, np.double)\n",
    "        bi = np.zeros(trainset.n_items, np.double)\n",
    "        pu = rng.normal(self.init_mean, self.init_std_dev,\n",
    "                        (trainset.n_users, self.n_factors))\n",
    "        qi = rng.normal(self.init_mean, self.init_std_dev,\n",
    "                        (trainset.n_items, self.n_factors))\n",
    "\n",
    "        if not self.biased:\n",
    "            global_mean = 0\n",
    "\n",
    "        for current_epoch in range(self.n_epochs):\n",
    "            if self.verbose:\n",
    "                print(\"Processing epoch {}\".format(current_epoch))\n",
    "            train_error = 0\n",
    "            for u, i, r in trainset.all_ratings():\n",
    "\n",
    "                # compute current error\n",
    "                dot = 0  # <q_i, p_u>\n",
    "                for f in range(self.n_factors):\n",
    "                    dot += qi[i, f] * pu[u, f]\n",
    "                err = r - (global_mean + bu[u] + bi[i] + dot)\n",
    "                train_error += abs(err)\n",
    "\n",
    "                # update biases\n",
    "                if self.biased:\n",
    "                    bu[u] += lr_bu * (err - reg_bu * bu[u])\n",
    "                    bi[i] += lr_bi * (err - reg_bi * bi[i])\n",
    "\n",
    "                # update factors\n",
    "                for f in range(self.n_factors):\n",
    "                    puf = pu[u, f]\n",
    "                    qif = qi[i, f]\n",
    "                    pu[u, f] += lr_pu * (err * qif - reg_pu * puf)\n",
    "                    qi[i, f] += lr_qi * (err * puf - reg_qi * qif)\n",
    "                    \n",
    "            self.train_error.append(train_error)\n",
    "\n",
    "        self.bu = bu\n",
    "        self.bi = bi\n",
    "        self.pu = pu\n",
    "        self.qi = qi\n",
    "\n",
    "    def estimate(self, u, i):\n",
    "        \"\"\"Predict rating of user u and movie i.\n",
    "        \n",
    "        Args:\n",
    "            u(int): user id\n",
    "            i(int): movie id\n",
    "        \n",
    "        Returns:\n",
    "            float: the predicted rating of user u and movie i. \n",
    "        \"\"\"\n",
    "\n",
    "        known_user = self.trainset.knows_user(u)\n",
    "        known_item = self.trainset.knows_item(i)\n",
    "\n",
    "        if self.biased:\n",
    "            est = self.trainset.global_mean\n",
    "\n",
    "            if known_user:\n",
    "                est += self.bu[u]\n",
    "\n",
    "            if known_item:\n",
    "                est += self.bi[i]\n",
    "\n",
    "            if known_user and known_item:\n",
    "                est += np.dot(self.qi[i], self.pu[u])\n",
    "\n",
    "        else:\n",
    "            if known_user and known_item:\n",
    "                est = np.dot(self.qi[i], self.pu[u])\n",
    "            else:\n",
    "                raise Exception('User and item are unkown.')\n",
    "\n",
    "        return est\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = CustomReader()\n",
    "filepath = helpers.get_train_file_path()\n",
    "data = Dataset.load_from_file(filepath, reader=reader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {  'n_factors': stats.randint(150,160),\n",
    "                'lr_bu': stats.uniform(0.004,0.007),\n",
    "                'lr_bi': stats.uniform(0.004,0.007),\n",
    "                'lr_qi': stats.uniform(0.01,0.03),\n",
    "                'lr_pu': stats.uniform(0.01,0.03),\n",
    "                'reg_bi': stats.uniform(0.02,0.05),\n",
    "                'reg_bu': stats.uniform(0.04,0.06),\n",
    "                'reg_qi': stats.uniform(0.04,0.08),\n",
    "                'reg_pu': stats.uniform(0.02,0.2),\n",
    "                'init_std_dev': stats.uniform(0.01,0.8),\n",
    "                'n_epochs': stats.randint(10,30)\n",
    "             }         \n",
    "        \n",
    "\n",
    "gs = RandomizedSearchCV(algo_class=SVD, param_distributions=param_grid, measures=['rmse'], \n",
    "                        cv=10, joblib_verbose=100, n_jobs=-1, n_iter=100)\n",
    "gs.fit(data)\n",
    "\n",
    "# best RMSE score\n",
    "print(gs.best_score['rmse'])\n",
    "\n",
    "# combination of parameters that gave the best RMSE score\n",
    "print(gs.best_params['rmse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame.from_dict(gs.cv_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RMSE results for different parameters\n",
    "\n",
    "Cross-validation over 10 folds.\n",
    "Run on Leonhard cluster (20 cores and 22GB mem)\n",
    "\n",
    "\n",
    "0.98460820897\n",
    "{'lr_bi': 0.0045699937900061235, 'lr_bu': 0.0053470080935120153, 'lr_pu': 0.017294772891100464, 'lr_qi': 0.016495757165001537, 'n_epochs': 26, 'n_factors': 159, 'reg_bi': 0.026026359248845211, 'reg_bu': 0.099924883620357285, 'reg_pu': 0.10778441193893745, 'reg_qi': 0.071670616244315685}\n",
    "\n",
    "0.98489843593\n",
    "{'lr_bi': 0.0043688979424132048, 'lr_bu': 0.005613464182452876, 'lr_pu': 0.022148955075059311, 'lr_qi': 0.012530626289208299, 'n_factors': 151, 'reg_bi': 0.042342905803236859, 'reg_bu': 0.073415041823889998, 'reg_pu': 0.12513844856777867, 'reg_qi': 0.060228735604464054}\n",
    "\n",
    "0.984953534195\n",
    "{'lr_bi': 0.0040080904244357771, 'lr_bu': 0.0083752718099860367, 'lr_pu': 0.010813216008005243, 'lr_qi': 0.018992188100229335, 'n_factors': 158, 'reg_bi': 0.02384386240305832, 'reg_bu': 0.087957272220067495, 'reg_pu': 0.17370665665508969, 'reg_qi': 0.042977558957037719}\n",
    "\n",
    "0.985070495179\n",
    "{'init_std_dev': 0.031184006269592716, 'lr_bi': 0.0048978641284463517, 'lr_bu': 0.010989040837895429, 'lr_pu': 0.016034035470675671, 'lr_qi': 0.012197663818154646, 'n_factors': 151, 'reg_bi': 0.029524162229769623, 'reg_bu': 0.042540872922616352, 'reg_pu': 0.071567945780504169, 'reg_qi': 0.075092708208885889}\n",
    "\n",
    "0.9853091859177997\n",
    "{'lr_bi': 0.0050565201838808, 'lr_bu': 0.005529901817482, 'lr_pu': 0.021009781711363945, 'lr_qi': 0.019237920706921686, 'n_factors': 153, 'reg_bi': 0.027507293418947705, 'reg_bu': 0.04792231303919493, 'reg_pu': 0.1051659555261933, 'reg_qi': 0.05739791764348274}\n",
    "\n",
    "0.985423383238\n",
    "{'lr_bi': 0.0045872175952940859, 'lr_bu': 0.0059198576112051132, 'lr_pu': 0.03996299827445985, 'lr_qi': 0.012744793911701359, 'n_factors': 156, 'reg_bi': 0.039006956026578499, 'reg_bu': 0.058835165460011773, 'reg_pu': 0.065999449644116956, 'reg_qi': 0.11943136846519176}\n",
    "\n",
    "0.98576635754\n",
    "{'lr_bi': 0.004388787077144584, 'lr_bu': 0.0077070689204476878, 'lr_pu': 0.037207361664974598, 'lr_qi': 0.011526606878613951, 'n_factors': 155, 'reg_bi': 0.055491394820528769, 'reg_bu': 0.025510174666992846, 'reg_pu': 0.073005652506841268, 'reg_qi': 0.084369830119022798}\n",
    "\n",
    "0.985920828862\n",
    "{'lr_bi': 0.0061067123779277675, 'lr_bu': 0.005972391928230663, 'lr_pu': 0.023802281518036983, 'lr_qi': 0.016117532546202691, 'n_factors': 157, 'reg_bi': 0.013775300394299965, 'reg_bu': 0.034301808303089626, 'reg_pu': 0.09627118462747386, 'reg_qi': 0.061245371260615522}\n",
    "\n",
    "0.986355638337\n",
    "{'lr_bi': 0.0053921528073649578, 'lr_bu': 0.014983628487378223, 'lr_pu': 0.025070307435290061, 'lr_qi': 0.0073965320227803123, 'n_factors': 154, 'reg_bi': 0.027365169456015866, 'reg_bu': 0.03585534141987403, 'reg_pu': 0.15019357711020351, 'reg_qi': 0.050166823853083298}\n",
    "\n",
    "0.986851655568\n",
    "{'lr_bi': 0.0053647824382532638, 'lr_bu': 0.0052769550628727633, 'lr_pu': 0.012545946659482476, 'lr_qi': 0.012795461232426109, 'n_factors': 156, 'reg_bi': 0.056418600300998704, 'reg_bu': 0.022556567389521144, 'reg_pu': 0.061086848339968164, 'reg_qi': 0.077168605512323629}\n",
    "\n",
    "0.9872175653005135\n",
    "{'lr_bi': 0.006088703690766571, 'lr_bu': 0.012744554096322995, 'lr_pu': 0.012380073174962966, 'lr_qi': 0.009130873179651982, 'n_factors': 158, 'reg_bi': 0.012919509150189782, 'reg_bu': 0.036795609500178635, 'reg_pu': 0.10361453028270178, 'reg_qi': 0.048785998289016745}\n",
    "\n",
    "0.988058743973\n",
    "{'lr_bi': 0.0045634712043475644, 'lr_bu': 0.01064562075669161, 'lr_pu': 0.012470219046795966, 'lr_qi': 0.0069239309430058314, 'n_factors': 160, 'reg_bi': 0.038064835563680136, 'reg_bu': 0.083204917488220814, 'reg_pu': 0.044129727640422105, 'reg_qi': 0.083532754108250978}\n",
    "\n",
    "0.9882588317180945\n",
    "{'lr_bi': 0.005572132295112126, 'lr_bu': 0.010459976354655289, 'lr_pu': 0.012621031473530591, 'lr_qi': 0.009189138000229718, 'n_factors': 81, 'reg_bi': 0.09508515857935072, 'reg_bu': 0.08100593615106191, 'reg_pu': 0.08560885565821767, 'reg_qi': 0.06136778252645429}\n",
    "\n",
    "0.9889400786056195\n",
    "{'lr_bi': 0.00505521532063321, 'lr_bu': 0.012181115620042492, 'lr_pu': 0.0094679873549249, 'lr_qi': 0.00612337262019204, 'n_factors': 108, 'reg_bi': 0.023237810934149287, 'reg_bu': 0.09931980200620626, 'reg_pu': 0.07865295413390713, 'reg_qi': 0.04964170302513018}\n",
    "\n",
    "0.9894911251394463\n",
    "{'lr_bi': 0.006439713022658003, 'lr_bu': 0.005220730820427025, 'lr_pu': 0.012121360196274768, 'lr_qi': 0.010296116770652414, 'n_factors': 98, 'reg_bi': 0.07326008897853639, 'reg_bu': 0.0654521219387276, 'reg_pu': 0.07673672028564435, 'reg_qi': 0.07732908168371602}\n",
    "\n",
    "0.992159817137\n",
    "{'lr_all': 0.0088540357639887227, 'n_factors': 94, 'reg_all': 0.060980144283391415}\n",
    "\n",
    "0.9922037152942101\n",
    "{'lr_all': 0.009404839806784696, 'n_factors': 83, 'reg_all': 0.06361145065359476}\n",
    "\n",
    "0.9923411994233705\n",
    "{'lr_all': 0.009518436883800755, 'n_factors': 98, 'reg_all': 0.06448898038350545}\n",
    "\n",
    "0.996356760492\n",
    "{'lr_all': 0.0069735838056049675, 'n_factors': 16, 'reg_all': 0.040538641816816053}\n",
    "\n",
    "0.996617863993\n",
    "{'lr_all': 0.0080655611939959484, 'n_epochs': 19, 'n_factors': 9, 'reg_all': 0.042201220509606799}\n",
    "\n",
    "0.996918766638\n",
    "{'lr_all': 0.010438622204618025, 'n_factors': 16, 'reg_all': 0.069969144045048129}\n",
    "\n",
    "0.998777808857\n",
    "{'n_factors': 5}\n",
    "\n",
    "0.999721712849\n",
    "{'lr_all': 0.0048483945439183485, 'n_factors': 9}\n",
    "\n",
    "1.00085021593\n",
    "{'lr_all': 0.0035314408264436933, 'n_epochs': 19, 'n_factors': 50, 'reg_all': 0.027105037999075404}\n",
    "\n",
    "1.00534587695\n",
    "{'lr_all': 0.0034656840329879137, 'n_epochs': 10, 'n_factors': 42, 'reg_all': 0.12231592623013628}\n",
    "\n",
    "1.00104676332\n",
    "{'lr_all': 0.0066032381482039656, 'n_epochs': 17, 'n_factors': 107, 'reg_all': 0.036362623151074552}\n",
    "\n",
    "1.00382744957\n",
    "{'lr_all': 0.0045664408289589759, 'n_epochs': 12, 'n_factors': 9, 'reg_all': 0.04029560227746723}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose optimal params from above\n",
    "n_epochs = 1\n",
    "algo = SVD(n_factors=159, lr_bi=0.0045699937900061235, lr_bu=0.0053470080935120153, lr_pu=0.017294772891100464, lr_qi=0.016495757165001537, reg_bi=0.026026359248845211, reg_bu=0.099924883620357285, reg_pu=0.10778441193893745, reg_qi=0.071670616244315685, n_epochs=n_epochs)\n",
    "\n",
    "# train \n",
    "algo.fit(data.build_full_trainset())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot error over epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-48210.31482988527, -6975.111217341403]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(algo.train_error)\n",
    "plt.plot(range(1,n_epochs+1), algo.train_error, 'r--')\n",
    "plt.legend(['Training Loss'])\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting\n",
    "We load the test data to predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_file_path = helpers.get_test_file_path()\n",
    "test_data = Dataset.load_from_file(test_file_path, reader=reader)\n",
    "testset = test_data.construct_testset(test_data.raw_ratings)\n",
    "predictions = algo.test(testset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to convert the predictions into the right format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = get_ratings_from_predictions(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can write the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = helpers.write_submission(ratings, 'submission_surprise_SVD_5.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
